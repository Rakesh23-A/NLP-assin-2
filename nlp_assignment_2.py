# -*- coding: utf-8 -*-
"""NLP Assignment-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I_gTrqVznbApH6Y1oKmy3zVVE1cw06Oc

A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.
Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.
1.	Convert the above paragraph into vectors using:i)	Word2vec
ii)	USE
iii)	ELMO
iv)	GP2
v)	Sentence-BERT
"""

paragraph='''A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.
Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.'''

import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords
import numpy as np
import gensim
from gensim.models import Word2Vec
from gensim import corpora,models,similarities

def essay_to_sentences(para):
    tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')
    raw_sentences=tokenizer.tokenize(para.strip())
    sentences=[]
    for raw_sentence in raw_sentences:
        if len(raw_sentence) > 0:
            sentences.append((raw_sentence))
    return sentences
sentences= essay_to_sentences(paragraph)


wordvecs=[nltk.word_tokenize(sent) for sent in sentences]
stops=list(set(stopwords.words("english")))

for i in wordvecs:
  for j in i:
    if j in stops:
      i.remove(j)
    elif len(j)==1:
      i.remove(j)

model=gensim.models.Word2Vec(wordvecs,min_count=1,size=32)
model['paragraph']

model.most_similar('sentence')

import tensorflow_hub as hub
use= hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")
embeddings=use(sentences)
print(embeddings)

print("shape= ",embeddings[0].shape)
print("The sentence: ",sentences[0],"\n is converted as : \n{}".format(embeddings[0]))

bert = hub.KerasLayer("https://tfhub.dev/google/nnlm-en-dim128/2")
embeddings2=bert(sentences)
print("shape=",embeddings2[0].shape)
print("The sentence: ",sentences[0],"\n is converted as : \n{}".format(embeddings2[0]))

import tensorflow_hub as hub
import tensorflow.compat.v1 as tf
tf.disable_eager_execution()

elmo=hub.Module("https://tfhub.dev/google/elmo/3",trainable=True)
embeddings=elmo(
    sentences,
    signature="default",
    as_dict=True)["elmo"]
init=tf.initialize_all_variables()
sess=tf.Session()
sess.run(init)
print("\n\n")
print(sess.run(embeddings[0]))
print("shape=",embeddings[0].shape)

"""2). Find named entities (NER) for the above paragraph?"""

import torch
!pip install -U sentence-transformers
import transformers
gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')
model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')
output=gptokenizer.encode(paragraph ,add_special_tokens=False,return_tensors="pt")
print("shape=",output.shape)
output

import torch
import transformers
gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')
model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')
output=gptokenizer.encode(paragraph ,add_special_tokens=False,return_tensors="pt")
print("shape=",output.shape)
output

import spacy
from spacy import displacy
ner=spacy.load('en')
result=ner(paragraph)

for word in result.ents:
  print(word.text,word.label_)

spacy.explain('GPE')
displacy.render(result,style="ent",jupyter=True)
resultss=ner("The doctor is a person who looks after the sick people and prescribes medicines so that the patient recovers fast. In order to become a doctor, a person has to study medicine. Doctors lead a hard life. Their life is very busy. They get up early in the morning and go to the hospital. They work without taking a break. They always remain polite so that patients feel comfortable with them. Since doctors work so hard we must realise their value.")
for word in resultss.ents:
  print(word.text,word.label_)

displacy.render(resultss,style="ent",jupyter=True)

"""3). Find similar sentences(repeated sentences) from the above paragraph?"""

from sentence_transformers import SentenceTransformer
sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')
se_embeddings = sbert_model.encode(sentences)
q1_vec= sbert_model.encode(sentences[0])

def cosine(u, v):
    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))

for sent in sentences:
  sim = cosine(q1_vec, sbert_model.encode([sent])[0])

  if sim>0.6:
    print("Sentence1 =",sentences[0],"\n \nSentence2=", sent, "\n\nsimilarity = ", sim,end="\n ----------------------------- \n")